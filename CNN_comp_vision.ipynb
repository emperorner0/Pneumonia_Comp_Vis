{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Pneumonia:-A-Computer-Vision-Task\" data-toc-modified-id=\"Pneumonia:-A-Computer-Vision-Task-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Pneumonia: A Computer Vision Task</a></span><ul class=\"toc-item\"><li><span><a href=\"#Business-Case\" data-toc-modified-id=\"Business-Case-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Business Case</a></span></li><li><span><a href=\"#Our-Data\" data-toc-modified-id=\"Our-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Our Data</a></span></li><li><span><a href=\"#Importations\" data-toc-modified-id=\"Importations-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Importations</a></span></li><li><span><a href=\"#Binary-Check\" data-toc-modified-id=\"Binary-Check-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Binary Check</a></span></li><li><span><a href=\"#PyTorch-Dataloader-Class\" data-toc-modified-id=\"PyTorch-Dataloader-Class-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>PyTorch Dataloader Class</a></span><ul class=\"toc-item\"><li><span><a href=\"#Class-Balance\" data-toc-modified-id=\"Class-Balance-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Class Balance</a></span></li></ul></li><li><span><a href=\"#Helper-Function\" data-toc-modified-id=\"Helper-Function-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Helper Function</a></span></li></ul></li><li><span><a href=\"#PyTorch-Model\" data-toc-modified-id=\"PyTorch-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>PyTorch Model</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#What-is-a-Neural-Network?\" data-toc-modified-id=\"What-is-a-Neural-Network?-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>What is a Neural Network?</a></span></li><li><span><a href=\"#PyTorch-and-TensorFlow\" data-toc-modified-id=\"PyTorch-and-TensorFlow-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>PyTorch and TensorFlow</a></span></li><li><span><a href=\"#Model-Details\" data-toc-modified-id=\"Model-Details-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>Model Details</a></span></li></ul></li><li><span><a href=\"#Model-Training\" data-toc-modified-id=\"Model-Training-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Model Training</a></span></li><li><span><a href=\"#Model-Testing\" data-toc-modified-id=\"Model-Testing-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Model Testing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deployable-Code\" data-toc-modified-id=\"Deployable-Code-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Deployable Code</a></span></li><li><span><a href=\"#Saving-and-Loading-Model\" data-toc-modified-id=\"Saving-and-Loading-Model-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Saving and Loading Model</a></span></li><li><span><a href=\"#TensorBoard\" data-toc-modified-id=\"TensorBoard-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>TensorBoard</a></span></li></ul></li></ul></li><li><span><a href=\"#Tensorflow-Keras-Model\" data-toc-modified-id=\"Tensorflow-Keras-Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Tensorflow-Keras Model</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Model-Compliation\" data-toc-modified-id=\"Model-Compliation-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Model Compliation</a></span></li><li><span><a href=\"#Testing-and-Training-Dataloaders\" data-toc-modified-id=\"Testing-and-Training-Dataloaders-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Testing and Training Dataloaders</a></span></li><li><span><a href=\"#Keras-Training\" data-toc-modified-id=\"Keras-Training-3.0.3\"><span class=\"toc-item-num\">3.0.3&nbsp;&nbsp;</span>Keras Training</a></span></li><li><span><a href=\"#Keras-Testing\" data-toc-modified-id=\"Keras-Testing-3.0.4\"><span class=\"toc-item-num\">3.0.4&nbsp;&nbsp;</span>Keras Testing</a></span></li><li><span><a href=\"#Keras-Model-Saving-and-Loading\" data-toc-modified-id=\"Keras-Model-Saving-and-Loading-3.0.5\"><span class=\"toc-item-num\">3.0.5&nbsp;&nbsp;</span>Keras Model Saving and Loading</a></span></li></ul></li></ul></li><li><span><a href=\"#Business-Application\" data-toc-modified-id=\"Business-Application-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Business Application</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumonia: A Computer Vision Task\n",
    "\n",
    "## Business Case\n",
    "\n",
    "Reading an **X-Ray** takes time. A [study](https://pubmed.ncbi.nlm.nih.gov/125436/) showed that with a **.2 second flash** of an **X-Ray** to a trained radiologist could predict a **70% true-positive rate** in diagnosing abnormal chest **X-Rays**. The issue is that still leaves a **30% False Negative rate** and these cases could prove fatal in the wrong person. The same study showed that given **unlimited time** to freely search the **X-Ray** the **true-positive rate** sky-rocketed to an incredible **96%**. When in life or death situations time and accuracy are of the utmost importance. After these times, when a patient receives a bill, it is important that the care have been quality due to the high costs of health care.\n",
    "\n",
    "We posit that if an **Artificial Neural Network** could be trained to recognize pneumonia cases in patients that we could save the insurance companies and patients large amounts of money, and save doctors large amounts of time so they could provide better health care.\n",
    "\n",
    "## Our Data\n",
    "\n",
    "Our dataset for this problem was provided on [Kaggle](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia).\n",
    "\n",
    "> There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia/Normal). <br><br>\n",
    "Chest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children’s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients’ routine clinical care.<br><br>\n",
    "For the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert.\n",
    "\n",
    "This data is a classic example of an **Image Classification** problem. In this notebook we will demonstrate the ability for an **Artificial Neural Network** to *learn* how to identify pneumonia in patient X-rays. The business applications of these sorts of algorithms are numerous and represent possible millions of dollars in savings for our health care system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:56:13.818136Z",
     "start_time": "2020-11-04T15:56:08.847134Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "np.random.seed(512)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "torch.manual_seed(512)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from skimage import io\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:56:13.823137Z",
     "start_time": "2020-11-04T15:56:13.820135Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:56:13.838134Z",
     "start_time": "2020-11-04T15:56:13.825137Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_palette(palette='crest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Check\n",
    "\n",
    "The PyTorch model has been designed in such a way that it can predict for 2 classes (Pneumonia/No Pneumonia) or 3 classes (No Pneumonia/Bacterial Pneumonia/Viral Pneumonia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:56:13.844134Z",
     "start_time": "2020-11-04T15:56:13.840137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change model between binary pneumonia, or a 3 class predicition \n",
    "two_classes = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Dataloader Class\n",
    "\n",
    "PyTorch has a Dataset inheritable class that can be used with the PyTorch framework. The Dataset inheritable class represents a Python iterable over a dataset that supports map-style or iterable-style datasets.\n",
    "\n",
    "* **Map-Style** - Represents a map of Key-Value pairs to data samples within the dataset.\n",
    "* **Iterable-Style** - Represents an iterable dataset like that which could be streamed from a database, remote server, or even generated in real-time. \n",
    "\n",
    "This uses the `__getitem__` method to implement data retrieval and is therefore a `map-style` dataset. The `__getitem__` method pulls an image path using root directory information and a pregenerated `CSV file` of image names and labels, and it then reads the generated image path. The image is transformed using the `PyTorch Transforms` or `None` if no transforms are supplied. The dataloader then returns a single image and its related label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:56:13.852136Z",
     "start_time": "2020-11-04T15:56:13.845136Z"
    }
   },
   "outputs": [],
   "source": [
    "class PneumoniaDataset(Dataset):\n",
    "    # Initialization of PneumoniaDataset for use with PyTorch\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    # For measuring length of dataset\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    # Retrieves one image at a time using the CSV and Rootdir\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = io.imread(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "        \n",
    "        # Performs passed PyTorch transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Returns single image with label from CSV\n",
    "        return (image, y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch transforms are a method for PyTorch to modify image data before it is fed into a model. This is most often used for regularization of input size and normalization before it is fed into the model. \n",
    "\n",
    "\n",
    "Below we have an image that is converted into a PIL Image, which allows for Pillow transforms. It then resizes all images to 32x32 pixels and grayscale to compress any RGB channels into a single output channel. These images are then converted to a tensor, and finally normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:56:13.859135Z",
     "start_time": "2020-11-04T15:56:13.853137Z"
    }
   },
   "outputs": [],
   "source": [
    "my_transforms = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((32,32)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[.5], std=[.5])\n",
    "        ])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:56:13.875136Z",
     "start_time": "2020-11-04T15:56:13.860136Z"
    }
   },
   "outputs": [],
   "source": [
    "if two_classes:\n",
    "    dataset = PneumoniaDataset(csv_file='pneumonia.csv', root_dir='xraydir',\n",
    "                               transform= my_transforms)\n",
    "else:\n",
    "    dataset = PneumoniaDataset(csv_file='test.csv', root_dir='xraydir',\n",
    "                               transform= my_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:56:14.137137Z",
     "start_time": "2020-11-04T15:56:13.877136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test image\n",
    "img = dataset[10][0]\n",
    "imgs = img.permute(1, 2, 0).numpy()\n",
    "plt.imshow(X=imgs[:,:, 0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:57:31.249833Z",
     "start_time": "2020-11-04T15:56:14.140136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af1491620b6443ea191011e990a8e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5856.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for image, label in tqdm(dataset):\n",
    "    labels.append(label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at class balance for our image data using the data generated by the outside script. As you can see we are facing a moderate imbalance. We address this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:57:31.337836Z",
     "start_time": "2020-11-04T15:57:31.250836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEICAYAAACuxNj9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbO0lEQVR4nO3dfZQddZ3n8ffH8CSCJCENG5NIcMzOGFgN2AYcHw4DLgRGJ6A4iw8QGMbgOWGVlXEEd48gGlddEQcFxmAigXHEqDxEFhcjCOoqDw1EyIMsLaBpE0ljwpNoNOGzf9Sv5ZLc7roJud2d9Od1zj236lu/qvrd5HZ/un5V95ZsExERMZAXDXUHIiJi+EtYRERErYRFRETUSlhERESthEVERNRKWERERK2ERYwoks6X9G9D3Y9WSDpCUs9Q9yMCEhaxE5L0bkldkp6WtEbSdyW9cYj6Ykm/K315TNLXJY0eir5EvBAJi9ipSPoQ8AXgU8D+wMuBS4GZQ9it19jeC3gFMAY4fwj7ErFNEhax05C0D3ABMMf2NbZ/Z/tPtr9j+8P9rPNNSb+R9ISkH0o6qGHZcZJWSHpK0q8l/VOpj5N0g6THJa2T9CNJtT9Ltp8EFgNTG/ZxmqSVZR8PSTpjgNd3jqRflLYrJJ3QsOxUST+W9DlJ6yU9LOnYhuVjJX1V0uqy/LqGZW+VtLS8np9IenXda4mRJ2ERO5PXA3sA127FOt8FpgD7AfcAX2tYNh84w/bewMHALaV+NtADdFAdvXwUqP3eHEljgOOB2xvKa4G3Ai8FTgMuknRoP5v4BfAmYB/g48C/SRrfsPww4AFgHPBZYL4klWVXAXsCB5XXelHp06HAAuAMYF/gy8BiSbvXvZ4YWRIWsTPZF3jM9sZWV7C9wPZTtjdQDQ+9phyhAPwJmCrppbbX276noT4eOKAcufzIA3/J2j2SHgceoxoW+3LD/v+37V+4chvwPapAaNbXb9pebftZ298AHgSmNzT5pe3LbW8CFpY+7l8C5Vjg/eV1/KnsC+B9wJdt32F7k+2FwAbg8Fb+/WLkSFjEzuS3wDhJu7TSWNIoSZ8uQztPAo+URePK8zuA44BfSrpN0utL/X8B3cD3ytDROTW7OtT2aKqjnsuAH0nao/ThWEm3l+Gsx8v+xjXbiKRTGoaLHqc62mls+5u+CdvPlMm9gEnAOtvrm2z2AODsvm2W7U4CXlbzmmKESVjEzuSnwB+ohnpa8W6qE99voRramVzqArB9l+2ZVMM21wGLSv0p22fbfgXwNuBDko6q25ntPwFfAQ4EDi5DPd8GPgfsXwLlxr79N5J0AHA5cCawb2m7rFnbJlYBY/u5CmsVMNf26IbHnra/3sJ2YwRJWMROw/YTwMeASyQdL2lPSbuWv94/22SVvamGXH5LNZ7/qb4FknaT9B5J+5Rf8k8Cm8qyt0p6ZTkf0FffVNc/SaOozkv8HngI2A3YHegFNpYT0kf3s/pLqM6L9JZtnUZ1ZFHL9hqqczOXShpT/k3eXBZfDrxf0mGqvETS30rau5Vtx8iRsIidiu3PAx8C/gfVL9ZVVH+NX9ek+ZXAL4FfAyt4/olngJOBR8oQ1fuB95b6FOD7wNNURzOX2r51gG79TNLTwHpgFnCC7XW2nwI+QHXEsp7qSGdxP69rBXBh2d+jwH8C/u8A+9zcyVTnWn5OdVL9rLLdLqrzFl8qfegGTt2K7cYIodz8KCIi6uTIIiIiaiUsIiKiVsIiIiJqJSwiIqJWSx9e2tGMGzfOkydPHupuRETsUO6+++7HbHc0W7ZThsXkyZPp6uoa6m5EROxQJP2yv2UZhoqIiFoJi4iIqJWwiIiIWgmLiIiolbCIiIhaCYuIiKiVsIiIiFoJi4iIqJWwiIiIWjvlJ7gjdnb/OP/Coe5CDENfOf3stm07RxYREVErYREREbUSFhERUSthERERtRIWERFRK2ERERG1EhYREVErYREREbUSFhERUavtYSFplKR7Jd1Q5g+UdIekByV9Q9Jupb57me8uyyc3bOPcUn9A0jHt7nNERDzfYBxZfBBY2TD/GeAi21OA9cDppX46sN72K4GLSjskTQVOAg4CZgCXSho1CP2OiIiirWEhaSLwt8BXyryAI4FvlSYLgePL9MwyT1l+VGk/E7ja9gbbDwPdwPR29jsiIp6v3UcWXwD+GXi2zO8LPG57Y5nvASaU6QnAKoCy/InS/s/1Juv8maTZkrokdfX29m7v1xERMaK1LSwkvRVYa/vuxnKTpq5ZNtA6zxXsebY7bXd2dHRsdX8jIqJ/7fyK8jcAfyfpOGAP4KVURxqjJe1Sjh4mAqtL+x5gEtAjaRdgH2BdQ71P4zoRETEI2nZkYftc2xNtT6Y6QX2L7fcAPwBOLM1mAdeX6cVlnrL8Ftsu9ZPK1VIHAlOAO9vV74iI2NJQ3PzoI8DVkj4J3AvML/X5wFWSuqmOKE4CsL1c0iJgBbARmGN70+B3OyJi5BqUsLB9K3BrmX6IJlcz2f4D8M5+1p8LzG1fDyMiYiD5BHdERNRKWERERK2ERURE1EpYRERErYRFRETUSlhERESthEVERNRKWERERK2ERURE1EpYRERErYRFRETUSlhERESthEVERNRKWERERK2ERURE1GrnPbj3kHSnpJ9JWi7p46V+haSHJS0tj2mlLkkXS+qWdJ+kQxu2NUvSg+Uxq799RkREe7Tz5kcbgCNtPy1pV+DHkr5bln3Y9rc2a38s1S1TpwCHAZcBh0kaC5wHdAIG7pa02Pb6NvY9IiIatPMe3Lb9dJndtTw8wCozgSvLercDoyWNB44BltheVwJiCTCjXf2OiIgttfWchaRRkpYCa6l+4d9RFs0tQ00XSdq91CYAqxpW7ym1/uqb72u2pC5JXb29vdv9tUREjGRtDQvbm2xPAyYC0yUdDJwL/BXwOmAs8JHSXM02MUB9833Ns91pu7Ojo2O79D8iIiqDcjWU7ceBW4EZtteUoaYNwFeB6aVZDzCpYbWJwOoB6hERMUjaeTVUh6TRZfrFwFuAn5fzEEgScDywrKyyGDilXBV1OPCE7TXATcDRksZIGgMcXWoRETFI2nk11HhgoaRRVKG0yPYNkm6R1EE1vLQUeH9pfyNwHNANPAOcBmB7naRPAHeVdhfYXtfGfkdExGbaFha27wMOaVI/sp/2Bub0s2wBsGC7djAiIlqWT3BHRESthEVERNRKWERERK2ERURE1EpYRERErYRFRETUSlhERESthEVERNRKWERERK2ERURE1EpYRERErYRFRETUSlhERESthEVERNRKWERERK123ilvD0l3SvqZpOWSPl7qB0q6Q9KDkr4habdS373Md5flkxu2dW6pPyDpmHb1OSIimmvnkcUG4EjbrwGmATPK7VI/A1xkewqwHji9tD8dWG/7lcBFpR2SpgInAQcBM4BLy933IiJikLQtLFx5uszuWh4GjgS+VeoLqe7DDTCzzFOWH1Xu0z0TuNr2BtsPU912dXq7+h0REVtq6zkLSaMkLQXWAkuAXwCP295YmvQAE8r0BGAVQFn+BLBvY73JOo37mi2pS1JXb29vO15ORMSI1dawsL3J9jRgItXRwKuaNSvP6mdZf/XN9zXPdqftzo6Ojm3tckRENDEoV0PZfhy4FTgcGC1pl7JoIrC6TPcAkwDK8n2AdY31JutERMQgaOfVUB2SRpfpFwNvAVYCPwBOLM1mAdeX6cVlnrL8Ftsu9ZPK1VIHAlOAO9vV74iI2NIu9U222XhgYbly6UXAIts3SFoBXC3pk8C9wPzSfj5wlaRuqiOKkwBsL5e0CFgBbATm2N7Uxn5HRMRm2hYWtu8DDmlSf4gmVzPZ/gPwzn62NReYu737GBERrcknuCMiolbCIiIiaiUsIiKiVsIiIiJqJSwiIqJWwiIiImolLCIiolbCIiIiaiUsIiKiVsIiIiJqJSwiIqJWwiIiImolLCIiolbCIiIiaiUsIiKiVjvvlDdJ0g8krZS0XNIHS/18Sb+WtLQ8jmtY51xJ3ZIekHRMQ31GqXVLOqddfY6IiObaeae8jcDZtu+RtDdwt6QlZdlFtj/X2FjSVKq74x0EvAz4vqT/WBZfAvxnqvtx3yVpse0Vbex7REQ0aOed8tYAa8r0U5JWAhMGWGUmcLXtDcDD5faqfXfU6y532EPS1aVtwiIiYpAMyjkLSZOpbrF6RymdKek+SQskjSm1CcCqhtV6Sq2/ekREDJK2h4WkvYBvA2fZfhK4DPgLYBrVkceFfU2brO4B6pvvZ7akLkldvb2926XvERFRaSksJN3cSq1Jm12pguJrtq8BsP2o7U22nwUu57mhph5gUsPqE4HVA9Sfx/Y82522Ozs6Olp5WRER0aIBw0LSHpLGAuMkjZE0tjwmU52EHmhdAfOBlbY/31Af39DsBGBZmV4MnCRpd0kHAlOAO4G7gCmSDpS0G9VJ8MVb8yIjIuKFqTvBfQZwFlUw3M1zQ0JPUl2hNJA3ACcD90taWmofBd4laRrVUNIjZR/YXi5pEdWJ643AHNubACSdCdwEjAIW2F7e6guMiIgXbsCwsP0vwL9I+q+2v7g1G7b9Y5qfb7hxgHXmAnOb1G8caL2IiGivli6dtf1FSX8NTG5cx/aVbepXREQMIy2FhaSrqK5gWgpsKmUDCYuIiBGg1Q/ldQJTbW9xyWpEROz8Wv2cxTLgP7SzIxERMXy1emQxDlgh6U5gQ1/R9t+1pVcRETGstBoW57ezExERMby1ejXUbe3uSEREDF+tXg31FM99H9NuwK7A72y/tF0di4iI4aPVI4u9G+clHc9z3+kUERE7uW361lnb1wFHbue+RETEMNXqMNTbG2ZfRPW5i3zmIiJihGj1aqi3NUxvpPoCwJnbvTcRETEstXrO4rR2dyQiIoavVm9+NFHStZLWSnpU0rclTWx35yIiYnho9QT3V6luOPQyqvtff6fUIiJiBGg1LDpsf9X2xvK4Asi9SyMiRohWw+IxSe+VNKo83gv8dqAVJE2S9ANJKyUtl/TBUh8raYmkB8vzmFKXpIsldUu6T9KhDduaVdo/KGnWtr7YiIjYNq2GxT8Afw/8BlgDnAjUnfTeCJxt+1XA4cAcSVOBc4CbbU8Bbi7zAMdS3Xd7CjAbuAyqcAHOAw6j+iDgeX0BExERg6PVsPgEMMt2h+39qMLj/IFWsL3G9j1l+ilgJdX5jpnAwtJsIXB8mZ4JXOnK7cBoSeOBY4AlttfZXg8sAWa0+gIjIuKFazUsXl1+UQNgex1wSKs7kTS5tL8D2N/2mrKdNcB+pdkEYFXDaj2l1l99833MltQlqau3t7fVrkVERAtaDYsXNQ79lKGhVj/9vRfwbeAs208O1LRJzQPUn1+w59nutN3Z0ZFz7xER21Orn+C+EPiJpG9R/aL+e2Bu3UqSdqUKiq/ZvqaUH5U03vaaMsy0ttR7gEkNq08EVpf6EZvVb22x3xERsR20dGRh+0rgHcCjQC/wdttXDbSOJAHzgZW2P9+waDHQd0XTLOD6hvop5aqow4EnyjDVTcDRksaUo5ujSy0iIgZJq0cW2F4BrNiKbb8BOBm4X9LSUvso8GlgkaTTgV8B7yzLbgSOA7qBZyhXW9leJ+kTwF2l3QXlnElERAySlsNia9n+Mc3PNwAc1aS9gTn9bGsBsGD79S4iIrbGNt3PIiIiRpaERURE1EpYRERErYRFRETUSlhERESthEVERNRKWERERK2ERURE1EpYRERErYRFRETUSlhERESthEVERNRKWERERK2ERURE1GrbV5Tv6OZ+50tD3YUYhv77284c6i5EDIm2HVlIWiBpraRlDbXzJf1a0tLyOK5h2bmSuiU9IOmYhvqMUuuWdE67+hsREf1r5zDUFcCMJvWLbE8rjxsBJE0FTgIOKutcKmmUpFHAJcCxwFTgXaVtREQMonbeKe+Hkia32HwmcLXtDcDDkrqB6WVZt+2HACRdXdpuze1dIyLiBRqKE9xnSrqvDFONKbUJwKqGNj2l1l99C5JmS+qS1NXb29uOfkdEjFiDHRaXAX8BTAPWABeWerN7dXuA+pZFe57tTtudHR0d26OvERFRDOrVULYf7ZuWdDlwQ5ntASY1NJ0IrC7T/dUjImKQDOqRhaTxDbMnAH1XSi0GTpK0u6QDgSnAncBdwBRJB0rajeok+OLB7HNERLTxyELS14EjgHGSeoDzgCMkTaMaSnoEOAPA9nJJi6hOXG8E5tjeVLZzJnATMApYYHt5u/ocERHNtfNqqHc1Kc8foP1cYG6T+o3AjduxaxERsZXydR8REVErYREREbUSFhERUSthERERtRIWERFRK2ERERG1EhYREVErYREREbUSFhERUSthERERtRIWERFRK2ERERG1EhYREVErYREREbUSFhERUattYSFpgaS1kpY11MZKWiLpwfI8ptQl6WJJ3ZLuk3RowzqzSvsHJc1qV38jIqJ/7TyyuAKYsVntHOBm21OAm8s8wLFUt1KdAswGLoMqXKjusHcYMB04ry9gIiJi8LQtLGz/EFi3WXkmsLBMLwSOb6hf6crtwOhyv+5jgCW219leDyxhywCKiIg2G+xzFvvbXgNQnvcr9QnAqoZ2PaXWX30LkmZL6pLU1dvbu907HhExkg2XE9xqUvMA9S2L9jzbnbY7Ozo6tmvnIiJGusEOi0fL8BLleW2p9wCTGtpNBFYPUI+IiEE02GGxGOi7omkWcH1D/ZRyVdThwBNlmOom4GhJY8qJ7aNLLSIiBtEu7dqwpK8DRwDjJPVQXdX0aWCRpNOBXwHvLM1vBI4DuoFngNMAbK+T9AngrtLuAtubnzSPiIg2a1tY2H5XP4uOatLWwJx+trMAWLAduxYREVtpuJzgjoiIYSxhERERtRIWERFRK2ERERG1EhYREVErYREREbUSFhERUSthERERtRIWERFRK2ERERG1EhYREVErYREREbUSFhERUSthERERtRIWERFRa0jCQtIjku6XtFRSV6mNlbRE0oPleUypS9LFkrol3Sfp0KHoc0TESDaURxZ/Y3ua7c4yfw5ws+0pwM1lHuBYYEp5zAYuG/SeRkSMcMNpGGomsLBMLwSOb6hf6crtwGhJ44eigxERI9VQhYWB70m6W9LsUtvf9hqA8rxfqU8AVjWs21NqERExSNp2D+4ab7C9WtJ+wBJJPx+grZrUvEWjKnRmA7z85S/fPr2MiAhgiI4sbK8uz2uBa4HpwKN9w0vleW1p3gNMalh9IrC6yTbn2e603dnR0dHO7kdEjDiDHhaSXiJp775p4GhgGbAYmFWazQKuL9OLgVPKVVGHA0/0DVdFRMTgGIphqP2BayX17f/fbf8fSXcBiySdDvwKeGdpfyNwHNANPAOcNvhdjogY2QY9LGw/BLymSf23wFFN6gbmDELXIiKiH8Pp0tmIiBimEhYREVErYREREbUSFhERUSthERERtRIWERFRK2ERERG1EhYREVErYREREbUSFhERUSthERERtRIWERFRK2ERERG1EhYREVErYREREbUSFhERUWuHCQtJMyQ9IKlb0jlD3Z+IiJFkhwgLSaOAS4BjganAuyRNHdpeRUSMHDtEWADTgW7bD9n+I3A1MHOI+xQRMWKousX18CbpRGCG7X8s8ycDh9k+s6HNbGB2mf1L4IFB7+jOaxzw2FB3IqIfeX9uPwfY7mi2YJfB7sk2UpPa81LO9jxg3uB0Z2SR1GW7c6j7EdFM3p+DY0cZhuoBJjXMTwRWD1FfIiJGnB0lLO4Cpkg6UNJuwEnA4iHuU0TEiLFDDEPZ3ijpTOAmYBSwwPbyIe7WSJLhvRjO8v4cBDvECe6IiBhaO8owVEREDKGERURE1EpYDFOSLOnChvl/knT+Vqx/qqReSUslrZD0vrZ0tA0kXSDpLUPdj9h2kjaV994ySd+UtOdQ96kVkjolXTzU/RiOEhbD1wbg7ZLGvYBtfMP2NOAI4FOS9t8uPWsz2x+z/f2h7ke8IL+3Pc32wcAfgfcPdYdaYbvL9geGuh/DUcJi+NpIdZXHf9t8gaQDJN0s6b7y/PKBNmR7LfAL4ABJV0i6WNJPJD1UPh3ft90PS7qrbPfjpTZZ0rKGNn8+wpF0q6SLJP1Q0kpJr5N0jaQHJX2yYZ0Plb8wl0k6q2G7KyVdLmm5pO9JenFZdkVfvyR9rPRpmaR5kpp9QDOGtx8Br5R0RHnPfEvSzyV9re//U9JrJd0m6W5JN0kaX+q3Suos0+MkPVKmT5V0naTvSHpY0pnlfXavpNsljS3tppX5+yRdK2lMw3Y/I+lOSf9P0ptK/QhJN5Tp6eXn5N7y/JeD/Q83nCQshrdLgPdI2mez+peAK22/GvgaMOBhs6RXAK8AuktpPPBG4K3Ap0ubo4EpVN/DNQ14raQ3t9DHP9p+M/CvwPXAHOBg4FRJ+0p6LXAacBhwOPA+SYeUdacAl9g+CHgceEeT7X/J9uvKX6gvLn2OHYSkXai+APT+UjoEOIvqC0FfAbxB0q7AF4ETbb8WWADMbWHzBwPvpnrPzgWesX0I8FPglNLmSuAj5WflfuC8hvV3sT299Kex3ufnwJvLNj8GfKqlF72T2iE+ZzFS2X5S0pXAB4DfNyx6PfD2Mn0V8Nl+NvFfJL2RakjrDNvryh9y19l+FljRMDR1dHncW+b3ovpl/quabvZ9OPJ+YLntNQCSHqL61P0bgWtt/67UrwHeVNZ72PbSsv7dwOQm2/8bSf8M7AmMBZYD36npUwy9F0vq+7/9ETAf+GvgTts9AGX5ZKo/FA4GlpT35yhgTQv7+IHtp4CnJD3Bc++L+4FXlz+yRtu+rdQXAt9sWP+a8tzfe28fYKGkKVRfL7RrC33aaSUshr8vAPcAXx2gTX8flvlG45ctNtjQMK2G5/9p+8uNDSVN5PlHoHv0s61nN9vus1Tvr4GGjRrbb6I6cmjc9x7ApUCn7VVl+Gvz/cfw9PtyvuzPShBs/n/e9x5Zbvv1Tbazkefef/299+D577++916dvvZ9/djcJ6gC6QRJk4FbW9jmTivDUMOc7XXAIuD0hvJPqL7yBOA9wI+3w65uAv5B0l4AkiZI2g94FNivDCntztYPA/0QOF7SnpJeApxA9ZdmK/p+OTxW+nXiQI1jh/UA0CHp9QCSdpV0UFn2CPDaMr1V//+2nwDW952PAE4Gbhtglc3tA/y6TJ+6NfveGeXIYsdwIdB4hPABYIGkDwO9VOcEXhDb35P0KuCn5S/Ap4H32l4r6QLgDuBhqnHcrdnuPZKuAO4spa/Yvrf8pVa37uOSLqcaVniE6jvCYidj+4/lgoaLy9DRLlRH1MuBzwGLVN2W4JZt2Pws4F9VXbr7EFv3s/JZqmGoD23jvncq+bqPiIiolWGoiIiolbCIiIhaCYuIiKiVsIiIiFoJi4iIqJWwiIiIWgmLiIio9f8BBLQNrIrAIakAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if two_classes:\n",
    "    sns.countplot(labels)\n",
    "    plt.xticks(ticks=(0,1), labels=('No Pneumonia', 'Pneumonia'))\n",
    "    plt.title('Class Balance')\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    sns.countplot(labels)\n",
    "    plt.xticks(ticks=(0,1,2), labels=('No Pneumonia', 'Bacterial Pnemonia', 'Viral Pneumonia'))\n",
    "    plt.title('Class Balance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below takes a generated PyTorch dataset and returns the weight of the classes within the dataset using the Sci-kit Learn implementation of `class_weight.compute_class_weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:57:31.343834Z",
     "start_time": "2020-11-04T15:57:31.338833Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_class_weights(dataset, balance='balanced'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns class weights for use in Neural Network using Sci-\n",
    "    Kit Learns class_weight function.\n",
    "    ---------------------------------------------------------\n",
    "    Dataset[PyTorch] - The dataset used for you network\n",
    "    Balance[String] - Optional input to determine balance of classes\n",
    "    ---------------------------------------------------------\n",
    "    \n",
    "    returns python list of class weights\"\"\"\n",
    "    \n",
    "    # List for labels for class weight calc\n",
    "    labels = []\n",
    "\n",
    "    # Pulling out labels from data\n",
    "    for image, label in tqdm(dataset):\n",
    "        labels.append(label.item())\n",
    "\n",
    "    # Using SKLearn to compute class weights\n",
    "    class_weights = list(class_weight.compute_class_weight(balance,\n",
    "                                         np.unique(labels), \n",
    "                                         labels))\n",
    "    \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:58:26.969878Z",
     "start_time": "2020-11-04T15:57:31.344833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e5d0d322d542efb7b3f54bc9ee67b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5856.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "weights = calc_class_weights(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Science offer several very competent and useful frameworks for building, maintaining, and deploying Neural Networks. Of these many frameworks two have set themselves apart from the rest of the chaff by being flexible and easily put into a production environment. These are **PyTorch** and **Tensorflow**. **PyTorch** being developed and maintained by Facebook and **Tensorflow** being developed and maintained by Google. These are the two most popular and widely used frameworks. \n",
    "\n",
    "### What is a Neural Network? \n",
    "\n",
    "* **Artificial Neural Networks** at the most base level explanation is an attempt to model how the human brain functions on a level that concerns learning in order to make predictions or draw inferences.\n",
    "\n",
    "\n",
    "* A deeper explanation describes that an **ANN** is comprised of **artificial neurons** that connect to other **artificial neurons** through **synaptic connections**. These **neurons** have an **edge** that is **weighted** through various transformations. Being passed through a **weighted edge** can decrease the strength of the signal between **layers** of **neurons**. Each **layer** can have a function that acts as a sort of gatekeeper which only allows a **neuron** to fire if it's signal reaches a certain threshold, this is known as an **activation function**. This is the analogous action that mimics learning. The final **layer** of **neurons** represents the **output** of the network. Predictions of the **ANN** are passed through a mathematical function that calculates the cost of the prediction, this cost function is known as the **loss function**. This **loss function** operates with **back-propogation** in order to pass information back through the **model** in order to calculate **gradients** and have the model learn.\n",
    "\n",
    "### PyTorch and TensorFlow\n",
    "\n",
    "The first model below is a **PyTorch** model. \n",
    "\n",
    "**PyTorch**, as previously stated, is a neural network framework developed and maintained by Facebook. The current trend shows that **PyTorch** and **Tensorflow** share similar interest within websearches, with **PyTorch** pulling slightly ahead. As seen in this image provided by Google Trends: \n",
    "\n",
    "![Google Trends](images/pyttf.png)\n",
    "![Google Trends](images/pyttf_chart.png)\n",
    "\n",
    "This increase in interest can be attributed to several things, including adoption of **PyTorch** by Silicon Valley front-runners like Tesla. \n",
    "\n",
    "It's also because of the difference in architecture of the frameworks from not just a data science standpoint, but also a software engineering standpoint. **Tensorflow** is a statically graphed architecture, and **PyTorch** is a dynamic architecture. An excellent explanation was posted on [StackOverflow](https://stackoverflow.com/questions/46154189/what-is-the-difference-of-static-computational-graphs-in-tensorflow-and-dynamic):\n",
    "\n",
    "> Both frameworks operate on tensors and view any model as a directed acyclic graph (DAG), but they differ drastically on how you can define them.<br><br>\n",
    "TensorFlow follows ‘data as code and code is data’ idiom. In TensorFlow you define graph statically before a model can run. All communication with outer world is performed via tf.Session object and tf.Placeholder which are tensors that will be substituted by external data at runtime. <br><br>\n",
    "In PyTorch things are way more imperative and dynamic: you can define, change and execute nodes as you go, no special session interfaces or placeholders. Overall, the framework is more tightly integrated with Python language and feels more native most of the times. When you write in TensorFlow sometimes you feel that your model is behind a brick wall with several tiny holes to communicate over. Anyways, this still sounds like a matter of taste more or less. <br><br>\n",
    "However, those approaches differ not only in a software engineering perspective: there are several dynamic neural network architectures that can benefit from the dynamic approach. Recall RNNs: with static graphs, the input sequence length will stay constant. This means that if you develop a sentiment analysis model for English sentences you must fix the sentence length to some maximum value and pad all smaller sequences with zeros. Not too convenient, huh. And you will get more problems in the domain of recursive RNNs and tree-RNNs. Currently Tensorflow has limited support for dynamic inputs via Tensorflow Fold. PyTorch has it by-default.\n",
    "\n",
    "![Directed Graph](images/graphmap.gif)\n",
    "This `gif` is an example of how any neural network model can be displayed as a **directed acyclic graph**.\n",
    "\n",
    "### Model Details\n",
    "\n",
    "We have chose to code our model in a way that takes advantage of the **Object-Oriented** nature of the framework. There-by making our model easily extensible, increasing our debugging capabilities, helping with tunability of our model's parameters, and finally making the model more deployable from a production standpoint.\n",
    "\n",
    "#### Convolutional Neural Network\n",
    "\n",
    "We have chosen to make our model a slightly more advanced form of **ANN**, the **Convolutional Neural Network**. We chose this because **CNN**s are generally better at **image classification** tasks. **CNN**s are named after layers that are within their architecture. This flavor of **ANN** make use of **Convolutional Layers**, which in the simplest terms apply **convolutional filters** to an image as they scan over it. These **convolutional filters** can scan an image for generalized features, and as the information is passed forward in the sequential model it can pick out more and more complex features within your image. This also allows for **feature reduction** within the model, which is something that a **Fully Connected** (or **Dense**) **layer** cannot deal with innately. \n",
    "\n",
    "According to [Machine Learning Mastery](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/), a **convolution** is:\n",
    "\n",
    "> In the context of a convolutional neural network, a convolution is a linear operation that involves the multiplication of a set of weights with the input, much like a traditional neural network. Given that the technique was designed for two-dimensional input, the multiplication is performed between an array of input data and a two-dimensional array of weights, called a filter or a kernel. <br><br>\n",
    "This systematic application of the same filter across an image is a powerful idea. If the filter is designed to detect a specific type of feature in the input, then the application of that filter systematically across the entire input image allows the filter an opportunity to discover that feature anywhere in the image. This capability is commonly referred to as translation invariance, e.g. the general interest in whether the feature is present rather than where it was present.\n",
    "\n",
    "#### Activation Function\n",
    "\n",
    "An **activation function** is a simple concept that relates back to the idea of the neural network being an analogous system to the brain. The function is a mathematical equation that represents a threshold at which the neuron will fire and thus send its signal on to the next layer. This can be numerous things, such as a linear function that makes the output proportional to the input, or a sigmoid function that returns a value between 0 and 1. These are just two of the numerous functions that can represent activations of the neurons.\n",
    "\n",
    "#### Loss Function\n",
    "\n",
    "**Neural Networks** are typically trained by using **stochastic gradient descent** and this requires a method to measure the loss of the network. A neural network can be cast as learning based on optimization, where you are optimizing the weights of neurons. It optimizes these weights via **gradient descent** and associated algorithms, these algorithms seek to reduce the **error** of the next step by finding optimal weights for the neurons. This **error term** can also be referred to as a **loss**. This **loss** is calculated by a **loss function**, which is a distillation of the model itself to a single value. \n",
    "\n",
    "> The cost function reduces all the various good and bad aspects of a possibly complex system down to a single number, a scalar value, which allows candidate solutions to be ranked and compared.<br><br>\n",
    "— Page 155, Neural Smithing: Supervised Learning in Feedforward Artificial Neural Networks, 1999.\n",
    "\n",
    "#### Optimizer Function\n",
    "\n",
    "**Loss functions** have a function that are closely akin to them, which with they work hand in hand to make an **ANN** work. This function is known as the **Optimizer function**. As we discussed before learning through an **ANN** is a function of optimization of loss. The **Optimizer** takes the information learned through the **loss function** and uses it to apply optimizations to the **ANN**, so that it may learn. It takes the guidance of the **loss function** and is able to tell the network where to change weights and by how much, so that learning may start taking place within the **ANN**.\n",
    "\n",
    "#### Training and Testing\n",
    "\n",
    "After we have initialized our **network** so that we have all of the required **layers**, **activation**, **loss**, and **optimizer** functions, we must finally feed **inputs** into our **ANN** so that it can utilize all of the aforementioned mathematical transformations to learn. The **ANN** passes the **inputs** through and produces **predictions** that are then measured by the **loss function**, so that it may **optimize** the weights. **Training**, as discussed previously, is ultimately a function of optimization.\n",
    "\n",
    "**Training** generally takes place on a shuffled sub-set of the dataset so that the **ANN** may learn to generalize from the data. Datasets are generally subdivided into a **training set** and a **test set**. The **test set** is never seen by the **ANN**, so that it can be used to evaluate how well the **ANN** learned to generalize from the provided training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:00:37.381159Z",
     "start_time": "2020-11-04T16:00:37.323159Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Creation of our CNN network\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, lr, epochs, batch_size, num_classes, class_weights):\n",
    "        # Inherit from the torch.nn module\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Saving arguments for __init__ purposes\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.class_weights = class_weights\n",
    "        self.loss_history = []\n",
    "        self.acc_history = []\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Convolutions with Batch Normalize layers, finished with a max pooling\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        nn.init.xavier_uniform(self.conv1.weight)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.maxpool1 = nn.MaxPool2d(2)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 64, 3)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.conv6 = nn.Conv2d(64, 64, 3)\n",
    "        self.bn6 = nn.BatchNorm2d(64)\n",
    "        self.maxpool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Calculates input dimensions \n",
    "        input_size = self.calc_input()\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, self.num_classes)\n",
    "\n",
    "        # Adam optimizer\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "        # Cross-Entropy Loss\n",
    "        self.loss = nn.CrossEntropyLoss(weight=torch.tensor(self.class_weights).float())\n",
    "        self.to(self.device)\n",
    "        self.get_data()\n",
    "    \n",
    "    # Calculate input sizes\n",
    "    def calc_input(self):\n",
    "        # Junk data to pass through for calc\n",
    "        batch_data = torch.zeros((1,1,32,32))\n",
    "        \n",
    "        # Layers to pass junk through\n",
    "        batch_data = self.conv1(batch_data)\n",
    "        batch_data = self.bn1(batch_data)\n",
    "        batch_data = self.conv2(batch_data)\n",
    "        batch_data = self.bn2(batch_data)\n",
    "        batch_data = self.conv3(batch_data)\n",
    "        batch_data = self.bn3(batch_data)\n",
    "        batch_data = self.maxpool1(batch_data)\n",
    "        batch_data = self.conv4(batch_data)\n",
    "        batch_data = self.bn4(batch_data)\n",
    "        batch_data = self.conv5(batch_data)\n",
    "        batch_data = self.bn5(batch_data)\n",
    "        batch_data = self.conv6(batch_data)\n",
    "        batch_data = self.bn6(batch_data)\n",
    "        batch_data = self.maxpool2(batch_data)\n",
    "        # Return product of the data size for programatic use in network\n",
    "        return int(np.prod(batch_data.size()))\n",
    "    \n",
    "    # Forward step layers\n",
    "    def forward(self, batch_data):\n",
    "        # Sending dataset to GPU if available\n",
    "        batch_data = torch.tensor(batch_data).to(self.device)\n",
    "        \n",
    "        # Six layers of 32 5px filters on 1 channel (grayscale) images\n",
    "        batch_data = self.conv1(batch_data)\n",
    "        batch_data = self.bn1(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "        \n",
    "        batch_data = self.conv2(batch_data)\n",
    "        batch_data = self.bn2(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "        \n",
    "        batch_data = self.conv3(batch_data)\n",
    "        batch_data = self.bn3(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "        \n",
    "        # First pooling layer to gather together the 3 previous feature convolutions, 2px filter\n",
    "        batch_data = self.maxpool1(batch_data)\n",
    "        \n",
    "        batch_data = self.conv4(batch_data)\n",
    "        batch_data = self.bn4(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "        \n",
    "        batch_data = self.conv5(batch_data)\n",
    "        batch_data = self.bn5(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "        \n",
    "        batch_data = self.conv6(batch_data)\n",
    "        batch_data = self.bn6(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "        \n",
    "        # Second pooling pass, 2px filter\n",
    "        batch_data = self.maxpool2(batch_data)\n",
    "\n",
    "        # Unrow data for dense layer\n",
    "        batch_data = batch_data.view(batch_data.size()[0], -1)\n",
    "        \n",
    "        # Dense layer takes calculated input size features and outputs class predictions\n",
    "        batch_data = F.relu(self.fc1(batch_data))\n",
    "        \n",
    "        classes = self.fc2(batch_data)\n",
    "        \n",
    "        return classes\n",
    "    \n",
    "    # Retrieve data from dataset, with custom training size, random seed, and shuffle\n",
    "    def get_data(self, test_size = .3, random_seed=42, shuffle_dataset=True):\n",
    "        \n",
    "        # Transformer that takes in an image and resizes it to 32x32 px and true Grayscale\n",
    "        self.my_transforms = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((32,32)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[.5], std=[.5])\n",
    "        ])\n",
    "        \n",
    "        # Takes the data class and stores the data from the web\n",
    "        # uses CSV file and rootdir to find images and then applies transformers\n",
    "        if self.num_classes == 2:\n",
    "            csvfile = 'pneumonia.csv'\n",
    "        else:\n",
    "            csvfile = 'test.csv'\n",
    "            \n",
    "        pnemonia_data = PneumoniaDataset(csv_file=csvfile, root_dir='xraydir',\n",
    "                           transform= my_transforms)\n",
    "        \n",
    "        # Creating data indices for training and test splits\n",
    "        dataset_size = len(pnemonia_data)\n",
    "        indices = list(range(dataset_size))\n",
    "        split = int(np.floor(test_size * dataset_size))\n",
    "        if shuffle_dataset :\n",
    "            np.random.seed(random_seed)\n",
    "            np.random.shuffle(indices)\n",
    "        train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "        # Creating data samplers\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        valid_sampler = SubsetRandomSampler(val_indices)\n",
    "        \n",
    "\n",
    "        self.train_loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size,\n",
    "#                                                     shuffle=True,\n",
    "                                                    sampler=train_sampler,\n",
    "                                                    num_workers=0)\n",
    "        self.test_loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size,\n",
    "#                                                     shuffle=True,\n",
    "                                                    sampler=valid_sampler,\n",
    "                                                    num_workers=0)\n",
    "        \n",
    "        # returns dataset for tweaking purposes\n",
    "        return self.train_loader, self.test_loader\n",
    "    \n",
    "    def weights_init(self):\n",
    "        if isinstance(self, nn.Conv2d):\n",
    "            nn.init.xavier_uniform(self.weight.data)\n",
    "        \n",
    "    # Network train method\n",
    "    def _train(self):\n",
    "        # Sets PyTorch's state to train\n",
    "        self.train()\n",
    "        \n",
    "        net_mods = []\n",
    "        for module in self.modules():\n",
    "            net_mods.append(module)\n",
    "\n",
    "        network = net_mods[0]\n",
    "        \n",
    "        images, labels = next(iter(self.train_loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        tb = SummaryWriter(log_dir='tensorboard/')\n",
    "        \n",
    "        tb.add_image('images', grid, 0)\n",
    "        tb.add_graph(network, images)\n",
    "        \n",
    "        # Training loop, taking in number of epochs\n",
    "        for i in range(self.epochs):\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = []\n",
    "            \n",
    "            # Inner training loop\n",
    "            for j, (inpt, label) in enumerate(self.train_loader):\n",
    "                self.optimizer.zero_grad() # Zeroes gradients to avoid contamination\n",
    "                label = label.to(self.device) # Sends labels to GPU\n",
    "                prediction = self.forward(inpt) # Forward steps predictions by passing inpt images\n",
    "                loss = self.loss(prediction, label) # Uses Cross-Entropy Loss to calculate loss \n",
    "                # Softmax takes a vector of k-real values and turns them to a vector that sums to 1\n",
    "                prediction = F.softmax(prediction, dim=1) \n",
    "                classes = torch.argmax(prediction, dim=1) # Finds max value of target function to return predicted classes\n",
    "                wrong = torch.where(classes != label, \n",
    "                                    torch.tensor([1.]).to(self.device),\n",
    "                                    torch.tensor([0.]).to(self.device)) # Finds where classes predicts incorrectly\n",
    "                                                                        # And assigns a true and false binary value\n",
    "                    \n",
    "                acc = 1 - torch.sum(wrong) / self.batch_size # calculates accuracy\n",
    "                \n",
    "                epoch_acc.append(acc.item()) # acc.item detatches the value from the tensor for operation\n",
    "                self.acc_history.append(acc.item()) # Same as above\n",
    "                epoch_loss += loss.item() # Same as above\n",
    "                \n",
    "                loss.backward() # Back propogates loss from the loss function for learning\n",
    "                self.optimizer.step() # Uses Adam to step forward in learning\n",
    "            print('Finish epoch', i+1, 'total loss %.3f' % epoch_loss,\n",
    "                  'accuracy %.3f' % np.mean(epoch_acc*100))\n",
    "            \n",
    "            tb.add_scalar('Loss', epoch_loss, i)\n",
    "            tb.add_scalar('Number incorrect', torch.sum(wrong), i)\n",
    "            tb.add_scalar('Accuracy', acc, i)\n",
    "            \n",
    "            tb.add_histogram('conv1.bias', network.conv1.bias, i)\n",
    "            tb.add_histogram('conv2.bias', network.conv2.bias, i)\n",
    "            tb.add_histogram('conv3.bias', network.conv3.bias, i)\n",
    "            tb.add_histogram('conv4.bias', network.conv4.bias, i)\n",
    "            tb.add_histogram('conv5.bias', network.conv5.bias, i)\n",
    "            tb.add_histogram('conv6.bias', network.conv6.bias, i)\n",
    "            \n",
    "            tb.add_histogram('conv1.weight', network.conv1.weight, i)\n",
    "            tb.add_histogram('conv2.weight', network.conv2.weight, i)\n",
    "            tb.add_histogram('conv3.weight', network.conv3.weight, i)\n",
    "            tb.add_histogram('conv4.weight', network.conv4.weight, i)\n",
    "            tb.add_histogram('conv5.weight', network.conv5.weight, i)\n",
    "            tb.add_histogram('conv6.weight', network.conv6.weight, i)\n",
    "            \n",
    "            tb.close()\n",
    "            \n",
    "            self.loss_history.append(epoch_loss)\n",
    "    \n",
    "    # Testing method\n",
    "    def _test(self):\n",
    "        # Sets PyTorch's test state\n",
    "        self.eval()\n",
    "        \n",
    "        # See train step for further notes on this section\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = []\n",
    "        \n",
    "        predictionlist = []\n",
    "        labellist = []\n",
    "        \n",
    "        for j, (inpt, label) in enumerate(self.test_loader):\n",
    "            with torch.no_grad():\n",
    "                label = label.to(self.device)\n",
    "                prediction = self.forward(inpt)\n",
    "                loss = self.loss(prediction, label)\n",
    "                prediction = F.softmax(prediction, dim=1)\n",
    "                classes = torch.argmax(prediction, dim=1)\n",
    "                wrong = torch.where(classes != label,\n",
    "                                    torch.tensor([1.]).to(self.device),\n",
    "                                    torch.tensor([0.]).to(self.device))\n",
    "                predictionlist.append(prediction.cpu())\n",
    "                labellist.append(label.cpu())\n",
    "                acc = 1 - torch.sum(wrong) / self.batch_size\n",
    "                epoch_acc.append(acc.item())\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "        print('total loss %.3f' % epoch_loss,\n",
    "              'accuracy %.3f' % np.mean(epoch_acc))\n",
    "        \n",
    "        prediction_list = []\n",
    "        for pred in predictionlist:\n",
    "            for j in pred:\n",
    "                prediction_list.append(torch.argmax(j).item())\n",
    "                \n",
    "        label_list = []\n",
    "        for label in labellist:\n",
    "            for i in label:\n",
    "                label_list.append(i.item())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            con_matx = confusion_matrix(label_list, prediction_list)\n",
    "            norm_con_matx = confusion_matrix(label_list, prediction_list,\n",
    "                                             normalize='true')\n",
    "            \n",
    "        print(classification_report(label_list, prediction_list))\n",
    "            \n",
    "        display(con_matx)\n",
    "        display(norm_con_matx)\n",
    "        \n",
    "        self.loss_history.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:00:38.156476Z",
     "start_time": "2020-11-04T16:00:38.153478Z"
    }
   },
   "outputs": [],
   "source": [
    "# net_mods = []\n",
    "# for module in network.modules():\n",
    "#     net_mods.append(module)\n",
    "    \n",
    "# net = net_mods[0]\n",
    "\n",
    "# net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:29:10.740503Z",
     "start_time": "2020-11-04T16:19:24.365108Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             832\n",
      "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
      "            Conv2d-3           [-1, 32, 26, 26]           9,248\n",
      "       BatchNorm2d-4           [-1, 32, 26, 26]              64\n",
      "            Conv2d-5           [-1, 32, 24, 24]           9,248\n",
      "       BatchNorm2d-6           [-1, 32, 24, 24]              64\n",
      "         MaxPool2d-7           [-1, 32, 12, 12]               0\n",
      "            Conv2d-8           [-1, 64, 10, 10]          18,496\n",
      "       BatchNorm2d-9           [-1, 64, 10, 10]             128\n",
      "           Conv2d-10             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-11             [-1, 64, 8, 8]             128\n",
      "           Conv2d-12             [-1, 64, 6, 6]          36,928\n",
      "      BatchNorm2d-13             [-1, 64, 6, 6]             128\n",
      "        MaxPool2d-14             [-1, 64, 3, 3]               0\n",
      "           Linear-15                   [-1, 50]          28,850\n",
      "           Linear-16                    [-1, 2]             102\n",
      "================================================================\n",
      "Total params: 141,208\n",
      "Trainable params: 141,208\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.23\n",
      "Params size (MB): 0.54\n",
      "Estimated Total Size (MB): 1.77\n",
      "----------------------------------------------------------------\n",
      "Finish epoch 1 total loss 9.450 accuracy 0.872\n",
      "Finish epoch 2 total loss 5.449 accuracy 0.935\n",
      "Finish epoch 3 total loss 5.027 accuracy 0.948\n",
      "Finish epoch 4 total loss 5.835 accuracy 0.932\n",
      "Finish epoch 5 total loss 4.591 accuracy 0.949\n",
      "Finish epoch 6 total loss 3.635 accuracy 0.961\n",
      "Finish epoch 7 total loss 3.774 accuracy 0.956\n",
      "Finish epoch 8 total loss 2.501 accuracy 0.970\n",
      "Finish epoch 9 total loss 1.778 accuracy 0.980\n",
      "Finish epoch 10 total loss 2.018 accuracy 0.977\n",
      "Finish epoch 11 total loss 1.840 accuracy 0.980\n",
      "Finish epoch 12 total loss 1.721 accuracy 0.979\n",
      "Finish epoch 13 total loss 1.223 accuracy 0.986\n",
      "Finish epoch 14 total loss 0.820 accuracy 0.990\n",
      "Finish epoch 15 total loss 1.592 accuracy 0.982\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize CNN\n",
    "if two_classes:\n",
    "    network = CNN(lr=0.001, batch_size=128, epochs=15, num_classes=2, class_weights=weights) \n",
    "    summary(network, (1, 32, 32))\n",
    "\n",
    "else:\n",
    "    network = CNN(lr=0.001, batch_size=128, epochs=25, num_classes=3, class_weights=weights)\n",
    "    summary(network, (1, 32, 32))\n",
    "\n",
    "# Trains CNN\n",
    "network._train()\n",
    "\n",
    "# Plotting loss and accuracy histories\n",
    "plt.plot(network.loss_history)\n",
    "plt.title('Loss History by Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "plt.plot(network.acc_history)\n",
    "plt.title('Accuracy History by Epoch')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:11:51.872768Z",
     "start_time": "2020-11-04T16:11:51.868769Z"
    }
   },
   "outputs": [],
   "source": [
    "def total_images(network):\n",
    "    return (len(iter(network.test_loader)) * network.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:09.502843Z",
     "start_time": "2020-11-04T16:11:52.181770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss 2.993 accuracy 0.955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92       494\n",
      "           1       0.96      0.97      0.97      1262\n",
      "\n",
      "    accuracy                           0.95      1756\n",
      "   macro avg       0.95      0.94      0.94      1756\n",
      "weighted avg       0.95      0.95      0.95      1756\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 445,   49],\n",
       "       [  32, 1230]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.90080972, 0.09919028],\n",
       "       [0.02535658, 0.97464342]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model tested 1792 images in 17.32 seconds.\n",
      "0.009664 seconds per image.\n"
     ]
    }
   ],
   "source": [
    "# Tests the network\n",
    "starts = time.perf_counter()\n",
    "network._test()\n",
    "finishs = time.perf_counter()\n",
    "\n",
    "times = finishs - starts\n",
    "print(f'Model tested {total_images(network)} images in {times:.4g} seconds.')\n",
    "print(f'{times/total_images(network):.4g} seconds per image.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployable Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:09.508844Z",
     "start_time": "2020-11-04T16:12:09.503842Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_image(img): \n",
    "    \n",
    "    \"\"\"Helper Function:\n",
    "       Takes in Image, returns tensor of transformed image.\n",
    "    \"\"\"\n",
    "    \n",
    "    my_transforms = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((32,32)),\n",
    "                transforms.Grayscale(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[.5], std=[.5])\n",
    "            ])\n",
    "    image = io.imread(img)\n",
    "    return my_transforms(image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:09.520841Z",
     "start_time": "2020-11-04T16:12:09.510844Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_prediction(img_path):\n",
    "    \"\"\"Helper function:\n",
    "    Takes the image path, passes the image path to the transform_image function,\n",
    "    and then feeds the image into our model for a prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    tensor = transform_image(img=img_path)\n",
    "    outputs = network.forward(tensor)\n",
    "    _, y_hat = outputs.max(1)\n",
    "    return y_hat.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:09.540843Z",
     "start_time": "2020-11-04T16:12:09.522843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(\"valid_xray/validxray3.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch explains their **State-Dictionaries** as:\n",
    "> In PyTorch, the learnable parameters (i.e. weights and biases) of an torch.nn.Module model are contained in the model’s parameters (accessed with model.parameters()). A state_dict is simply a Python dictionary object that maps each layer to its parameter tensor. Note that only layers with learnable parameters (convolutional layers, linear layers, etc.) and registered buffers (batchnorm’s running_mean) have entries in the model’s state_dict. Optimizer objects (torch.optim) also have a state_dict, which contains information about the optimizer’s state, as well as the hyperparameters used.<br><br>\n",
    "Because state_dict objects are Python dictionaries, they can be easily saved, updated, altered, and restored, adding a great deal of modularity to PyTorch models and optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:09.554842Z",
     "start_time": "2020-11-04T16:12:09.542841Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), 'models/xray_cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:09.587842Z",
     "start_time": "2020-11-04T16:12:09.556843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=576, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=2, bias=True)\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = CNN(lr=0.001, batch_size=128, epochs=15, num_classes=2, class_weights=weights) \n",
    "model.load_state_dict(torch.load('models/xray_cnn.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow offers a free service that will allow you to host you TensorBoard experiments for all to view. We have decided to utilize this feature:\n",
    "\n",
    "[TensorBoard](https://tensorboard.dev/experiment/4zgLN2tXRbWX2agsMM49eA/#scalars&run=.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TensorFlow** is a **machine learning** framework that is developed and maintained by **Google**. In the intervening years, as the role of **Data Scientists** and **Machine Learning Engineers** has grown, numerous frameworks have sprung up and faded away. One that has survived, and is considered the epitome of Python machine learning libraries, is **TensorFlow**. \n",
    "\n",
    "**TensforFlow** has went through one large iteration. It moved from **TensorFlow** to it's current state as **TensorFlow 2.0**. This included several very important updates to the library that made for greatly expanded ease of use and deployment. Some, but not all of those additions, were:\n",
    "\n",
    "* Many old **TensorFlow** libraries were deprecated or combined to make it easier to navigate and find what you need.\n",
    "* A switch to **Eager Execution** made it so that you didn't need to start a session, you could work in a more Pythonic manner, and made debugging easier and quicker among a litany of other effects.\n",
    "* During the era of **TensorFlow 1.0**, **Keras** was a separate library that gave a high-level wrapper that would allow for rapid iteration and deploying. It has now been added to the **TensorFlow Core**, so that it can be better utilized.\n",
    "\n",
    "\n",
    "We have chosen to replicate, very closely, the network architecture of the **PyTorch model**. This is to compare how closely the two architectures perform on the same task under similar circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:09.920843Z",
     "start_time": "2020-11-04T16:12:09.594843Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dropout\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:11.323841Z",
     "start_time": "2020-11-04T16:12:09.921844Z"
    }
   },
   "outputs": [],
   "source": [
    "# Squential Model\n",
    "model = models.Sequential()\n",
    "\n",
    "# 3 Convolutional layers with batch norms and relu activation\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(32, 32, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Max pooling layer\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# 30% random dropout\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "# 3 additional Convolutional layers with batch norms\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "        \n",
    "# Max pooling layer\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Second dropout layer at 30%\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "# Flatten to feed into 2 dense layers to get output\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) # Sigmoid to output between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:11.332842Z",
     "start_time": "2020-11-04T16:12:11.324844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                28850     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 113,925\n",
      "Trainable params: 113,413\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Compliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:11.352841Z",
     "start_time": "2020-11-04T16:12:11.334843Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model compilation, optimizer is Adam with a -1e4 LR and a Focal Cross Entropy loss function\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=.0001),\n",
    "              loss=tfa.losses.SigmoidFocalCrossEntropy(from_logits=True),\n",
    "              metrics=['accuracy', 'Precision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Training Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:11.355844Z",
     "start_time": "2020-11-04T16:12:11.353844Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "train_data_dir = 'xrays/train'\n",
    "test_data_dir = 'xrays/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:11.889841Z",
     "start_time": "2020-11-04T16:12:11.356844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 files belonging to 2 classes.\n",
      "Using 4173 files for training.\n"
     ]
    }
   ],
   "source": [
    "# using the in-built Kerass data pre-processor to load data for training\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    label_mode='binary',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:12.045408Z",
     "start_time": "2020-11-04T16:12:11.890843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 files belonging to 2 classes.\n",
      "Using 124 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# using the in-built Kerass data pre-processor to load data for testing\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    label_mode='binary',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:12.050412Z",
     "start_time": "2020-11-04T16:12:12.046408Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shuffle data with each iteration pass\n",
    "train_ds = train_ds.shuffle(128, reshuffle_each_iteration=True)\n",
    "test_ds = test_ds.shuffle(128, reshuffle_each_iteration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:12:12.056409Z",
     "start_time": "2020-11-04T16:12:12.051411Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zip weights and labels for use in model fit\n",
    "weight_dict = dict(zip([0,1], weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:17:00.377332Z",
     "start_time": "2020-11-04T16:12:12.057412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "33/33 [==============================] - 2s 49ms/step - loss: 0.0850 - accuracy: 0.3348 - precision: 0.9446 - val_loss: 0.0774 - val_accuracy: 0.3790 - val_precision: 0.0000e+00\n",
      "Epoch 2/15\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0779 - accuracy: 0.5131 - precision: 0.9990 - val_loss: 0.0764 - val_accuracy: 0.3790 - val_precision: 0.0000e+00\n",
      "Epoch 3/15\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0757 - accuracy: 0.6530 - precision: 0.9957 - val_loss: 0.0773 - val_accuracy: 0.7016 - val_precision: 0.9762\n",
      "Epoch 4/15\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0736 - accuracy: 0.7218 - precision: 0.9979 - val_loss: 0.0693 - val_accuracy: 0.7016 - val_precision: 0.9762\n",
      "Epoch 5/15\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0727 - accuracy: 0.7532 - precision: 0.9971 - val_loss: 0.0990 - val_accuracy: 0.8306 - val_precision: 0.8182\n",
      "Epoch 6/15\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0726 - accuracy: 0.7762 - precision: 0.9958 - val_loss: 0.0870 - val_accuracy: 0.8387 - val_precision: 0.8701\n",
      "Epoch 7/15\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0716 - accuracy: 0.7930 - precision: 0.9991 - val_loss: 0.1164 - val_accuracy: 0.7903 - val_precision: 0.7629\n",
      "Epoch 8/15\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0716 - accuracy: 0.8057 - precision: 0.9965 - val_loss: 0.1237 - val_accuracy: 0.7661 - val_precision: 0.7400\n",
      "Epoch 9/15\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0715 - accuracy: 0.8184 - precision: 0.9966 - val_loss: 0.1214 - val_accuracy: 0.7661 - val_precision: 0.7449\n",
      "Epoch 10/15\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0718 - accuracy: 0.8162 - precision: 0.9953 - val_loss: 0.1073 - val_accuracy: 0.8226 - val_precision: 0.8090\n",
      "Epoch 11/15\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0707 - accuracy: 0.8349 - precision: 0.9983 - val_loss: 0.1061 - val_accuracy: 0.8226 - val_precision: 0.8090\n",
      "Epoch 12/15\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0708 - accuracy: 0.8416 - precision: 0.9979 - val_loss: 0.0710 - val_accuracy: 0.8387 - val_precision: 0.9254\n",
      "Epoch 13/15\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0697 - accuracy: 0.8500 - precision: 0.9996 - val_loss: 0.0776 - val_accuracy: 0.8226 - val_precision: 0.9104\n",
      "Epoch 14/15\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0698 - accuracy: 0.8684 - precision: 0.9984 - val_loss: 0.0829 - val_accuracy: 0.8306 - val_precision: 0.8889\n",
      "Epoch 15/15\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0697 - accuracy: 0.8574 - precision: 0.9992 - val_loss: 0.0666 - val_accuracy: 0.8065 - val_precision: 0.9649\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=15, validation_data=test_ds, class_weight=weight_dict, workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:17:00.475332Z",
     "start_time": "2020-11-04T16:17:00.378334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:17:00.943331Z",
     "start_time": "2020-11-04T16:17:00.476330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.8065 - precision: 0.9649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06662774831056595, 0.8064516186714172, 0.9649122953414917]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:17:02.899331Z",
     "start_time": "2020-11-04T16:17:00.944333Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('models/keras_xray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:17:04.208330Z",
     "start_time": "2020-11-04T16:17:02.900331Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstructed_model = models.load_model('models/keras_xray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:17:04.217333Z",
     "start_time": "2020-11-04T16:17:04.209330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                28850     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 113,925\n",
      "Trainable params: 113,413\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reconstructed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [study](https://pubmed.ncbi.nlm.nih.gov/125436/) which showed that a trained radiologist or physician can determine abnormality in a chest x-ray with only a .2 second flash at a 70% true positive rate proves the ability of a highly trained human. Fortunately, in our time we can train computers to perform repetitive, specialized tasks. \n",
    "\n",
    "#### Computational costs \n",
    "\n",
    "The contrast to the cost of a trained medical professional reading an X-Ray is the cost of computation. Computational costs have been driven down by a large offering of cloud services that can host, run, and store anything and everything you could think of. This is wonderful and provides a myriad of options for the method, but one of the largest and most robust is **Amazon Web Services (AWS)**. \n",
    "\n",
    "We are going to take a further look at the costs associated with **AWS** in relation to deploying our model.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"Images/computingcost.png\" />\n",
    "</p>\n",
    "\n",
    "These are the cheaper options that do not require that storage be paid for separately. \n",
    "\n",
    "The models that we have built in this notebook were trained on an **Nvidia RTX 2070**. This consumer GPU provides **280 TensorCores** at **60 TFLOPS**. **AWS** use the latest in **Nvidia** hardware which is the **T4** GPU. The **T4** has **320 TensorCores** rated at **130 TFLOPS**. \n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"Images/2070perf.png\" align='left'/>\n",
    "    <img src=\"Images/t4perf.png\" align='center' />\n",
    "</p>\n",
    "\n",
    "\n",
    "It is an option to run a self-made **Deep Learning Network** but the start up costs, maintenance, and labor required to run and maintain your own *local* **deep learning network** are more than likely prohibitive. Therefore these operations are significantly more likely to be **cloud based deployments** also known as **PaaS (Platform as a Service**. \n",
    "\n",
    "Referring back to the price chart figure above we can see that there are some moderately powerful options that could provide serious throughput for our network. However we are working on a relatively light weight model and therefore don't require a large series of parallel GPUs or dense core counts. The `g4dn.4xlarge` would be more that enough processing power and space for us to pass our data through. Running at just over $1.20 per hour it could be assumed that having a machine learning engineer and a small cloud setup could process tens of thousands of x-rays daily.\n",
    "\n",
    "#### Costs of Prediction via model\n",
    "\n",
    "Our model processed images at approximately **one hundreth of a second each**. That would mean, in ideal conditions, the model could theoretically make predictions on approximately **360,000** x-rays per hour. Therefore the average cost of an x-ray read of our model at the $1.20 per hour tear is approximately **3.333-6e cents per reading**.  \n",
    "\n",
    "#### Cost of Prediction via Doctor\n",
    "\n",
    "It is difficult to find exacting numbers on the cost a doctor or radiologist individually charge per reading of the x-ray. However we can surmise that, given the average cost in the US of a chest x-ray being [203 USD](https://health.costhelper.com/x-rays.html#:~:text=For%20patients%20without%20health%20insurance,the%20number%20of%20views%20taken.), the fee for a reading of the x-ray is appoximately 20% of the total cost thus making the cost to read ~46 USD.\n",
    "\n",
    "## Summation \n",
    "\n",
    "Our model, theoretically, could outperform a large team of doctors all observing a series of x-rays for .2 seconds each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env2",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "465.455px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
